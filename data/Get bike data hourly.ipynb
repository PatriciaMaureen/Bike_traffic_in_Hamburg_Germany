{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1e482c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Datastream IDs: [11797, 11801, 11805, 11821, 11825, 11829, 11833, 11837, 11841, 11845, 11849, 11857, 11873, 11877, 11881, 11885, 11897, 11901, 11905, 11909, 11913, 11917, 11921, 11925, 11929, 11933, 11941, 11957, 11965, 11977, 11993, 12005, 12009, 12013, 12017, 12021, 12025, 12029, 12033, 12037, 12041, 12045, 12049, 12053, 12057, 12061, 12065, 12073, 12085, 12097, 12109, 12117, 12121, 12125, 12129, 12133, 12137, 12141, 12543, 12547, 12551, 12555, 12559, 12563, 12567, 12571, 12575, 12579, 12583, 12587, 12591, 12595, 12599, 12607, 12611, 12615, 12619, 12720, 12724, 12728, 12732, 12736, 12740, 12744, 12748, 12752, 12756, 12764, 12768, 12772, 12776, 12780, 12784, 12788, 12792, 12796, 12818, 12822, 12826, 12830]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import datetime\n",
    "\n",
    "# Function to fetch data from a URL and handle HTTP errors\n",
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Base URL to fetch things with correct layerName\n",
    "base_url = (\n",
    "    \"https://iot.hamburg.de/v1.0/Things?\"\n",
    "    \"$filter=Datastreams/properties/serviceName eq 'HH_STA_HamburgerRadzaehlnetz' \"\n",
    "    \"and Datastreams/properties/layerName eq 'Anzahl_Fahrraeder_Zaehlstelle_1-Stunde'&\"\n",
    "    \"$expand=Datastreams($filter=properties/layerName eq 'Anzahl_Fahrraeder_Zaehlstelle_1-Stunde')\"\n",
    ")\n",
    "\n",
    "# Fetch things\n",
    "things_data = fetch_data(base_url)\n",
    "things = things_data['value']\n",
    "\n",
    "# Collect Datastreams\n",
    "datastreams = []\n",
    "for thing in things:\n",
    "    for datastream in thing['Datastreams']:\n",
    "        datastreams.append(datastream)\n",
    "\n",
    "# Extract Datastream IDs for hourly data\n",
    "hourly_datastream_ids = [ds['@iot.id'] for ds in datastreams]\n",
    "\n",
    "print(f\"Hourly Datastream IDs: {hourly_datastream_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ae12a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DatastreamID</th>\n",
       "      <th>PhenomenonTime</th>\n",
       "      <th>ResultTime</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11797</td>\n",
       "      <td>2024-05-25T23:00:00Z/2024-05-25T23:59:59Z</td>\n",
       "      <td>2024-05-27T00:54:25.823Z</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11797</td>\n",
       "      <td>2024-05-25T22:00:00Z/2024-05-25T22:59:59Z</td>\n",
       "      <td>2024-05-27T00:54:25.814Z</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11797</td>\n",
       "      <td>2024-05-25T21:00:00Z/2024-05-25T21:59:59Z</td>\n",
       "      <td>2024-05-26T00:54:27.521Z</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11797</td>\n",
       "      <td>2024-05-25T20:00:00Z/2024-05-25T20:59:59Z</td>\n",
       "      <td>2024-05-26T00:54:27.511Z</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11797</td>\n",
       "      <td>2024-05-25T19:00:00Z/2024-05-25T19:59:59Z</td>\n",
       "      <td>2024-05-26T00:54:27.503Z</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146009</th>\n",
       "      <td>12830</td>\n",
       "      <td>2024-03-26T07:00:00Z/2024-03-26T07:59:59Z</td>\n",
       "      <td>2024-03-27T00:54:47.03Z</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146010</th>\n",
       "      <td>12830</td>\n",
       "      <td>2024-03-26T06:00:00Z/2024-03-26T06:59:59Z</td>\n",
       "      <td>2024-03-27T00:54:47.022Z</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146011</th>\n",
       "      <td>12830</td>\n",
       "      <td>2024-03-26T05:00:00Z/2024-03-26T05:59:59Z</td>\n",
       "      <td>2024-03-27T00:54:47.015Z</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146012</th>\n",
       "      <td>12830</td>\n",
       "      <td>2024-03-26T04:00:00Z/2024-03-26T04:59:59Z</td>\n",
       "      <td>2024-03-27T00:54:47.006Z</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146013</th>\n",
       "      <td>12830</td>\n",
       "      <td>2024-03-26T03:00:00Z/2024-03-26T03:59:59Z</td>\n",
       "      <td>2024-03-27T00:54:46.999Z</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146014 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DatastreamID                             PhenomenonTime  \\\n",
       "0              11797  2024-05-25T23:00:00Z/2024-05-25T23:59:59Z   \n",
       "1              11797  2024-05-25T22:00:00Z/2024-05-25T22:59:59Z   \n",
       "2              11797  2024-05-25T21:00:00Z/2024-05-25T21:59:59Z   \n",
       "3              11797  2024-05-25T20:00:00Z/2024-05-25T20:59:59Z   \n",
       "4              11797  2024-05-25T19:00:00Z/2024-05-25T19:59:59Z   \n",
       "...              ...                                        ...   \n",
       "146009         12830  2024-03-26T07:00:00Z/2024-03-26T07:59:59Z   \n",
       "146010         12830  2024-03-26T06:00:00Z/2024-03-26T06:59:59Z   \n",
       "146011         12830  2024-03-26T05:00:00Z/2024-03-26T05:59:59Z   \n",
       "146012         12830  2024-03-26T04:00:00Z/2024-03-26T04:59:59Z   \n",
       "146013         12830  2024-03-26T03:00:00Z/2024-03-26T03:59:59Z   \n",
       "\n",
       "                      ResultTime  Result  \n",
       "0       2024-05-27T00:54:25.823Z      26  \n",
       "1       2024-05-27T00:54:25.814Z      40  \n",
       "2       2024-05-26T00:54:27.521Z      84  \n",
       "3       2024-05-26T00:54:27.511Z     132  \n",
       "4       2024-05-26T00:54:27.503Z     158  \n",
       "...                          ...     ...  \n",
       "146009   2024-03-27T00:54:47.03Z     783  \n",
       "146010  2024-03-27T00:54:47.022Z     339  \n",
       "146011  2024-03-27T00:54:47.015Z      99  \n",
       "146012  2024-03-27T00:54:47.006Z      22  \n",
       "146013  2024-03-27T00:54:46.999Z       4  \n",
       "\n",
       "[146014 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Current date (May 25, 2024)\n",
    "end_date = datetime.datetime(2024, 5, 26)\n",
    "start_date = datetime.datetime(2023, 5, 25)\n",
    "\n",
    "# List of correct Datastream IDs for hourly data\n",
    "datastream_ids = [11797, 11801, 11805, 11821, 11825, 11829, 11833, 11837, 11841, 11845, 11849, 11857, 11873, 11877, 11881, 11885, 11897, 11901, 11905, 11909, 11913, 11917, 11921, 11925, 11929, 11933, 11941, 11957, 11965, 11977, 11993, 12005, 12009, 12013, 12017, 12021, 12025, 12029, 12033, 12037, 12041, 12045, 12049, 12053, 12057, 12061, 12065, 12073, 12085, 12097, 12109, 12117, 12121, 12125, 12129, 12133, 12137, 12141, 12543, 12547, 12551, 12555, 12559, 12563, 12567, 12571, 12575, 12579, 12583, 12587, 12591, 12595, 12599, 12607, 12611, 12615, 12619, 12720, 12724, 12728, 12732, 12736, 12740, 12744, 12748, 12752, 12756, 12764, 12768, 12772, 12776, 12780, 12784, 12788, 12792, 12796, 12818, 12822, 12826, 12830]\n",
    "\n",
    "# Fetch observations for each Datastream ID\n",
    "all_data = []\n",
    "\n",
    "for datastream_id in datastream_ids:\n",
    "    observations_url = (\n",
    "        f\"https://iot.hamburg.de/v1.0/Datastreams({datastream_id})/Observations?\"\n",
    "        f\"$filter=phenomenonTime ge {start_date.isoformat()}Z and phenomenonTime le {end_date.isoformat()}Z&\"\n",
    "        \"$orderby=phenomenonTime desc\"\n",
    "    )\n",
    "    \n",
    "    observations_data = fetch_data(observations_url)\n",
    "    observations = observations_data['value']\n",
    "    \n",
    "    while '@iot.nextLink' in observations_data:\n",
    "        next_url = observations_data['@iot.nextLink']\n",
    "        sleep(randint(1,3000)/1000)  # Respectful pause between requests\n",
    "        observations_data = fetch_data(next_url)\n",
    "        observations.extend(observations_data['value'])\n",
    "    \n",
    "    # Extract and store relevant data\n",
    "    for observation in observations:\n",
    "        row = {\n",
    "            'DatastreamID': datastream_id,\n",
    "            'PhenomenonTime': observation['phenomenonTime'],\n",
    "            'ResultTime': observation['resultTime'],\n",
    "            'Result': observation['result']\n",
    "        }\n",
    "        all_data.append(row)\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "data = pd.DataFrame(all_data)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af61c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('bike_data_hourly.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f83437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
